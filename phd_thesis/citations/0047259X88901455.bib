@article{verducci,
    title = "Estimating multiple rater agreement for a rare diagnosis",
    journal = "Journal of Multivariate Analysis",
    volume = "27",
    number = "2",
    pages = "512 - 535",
    year = "1988",
    issn = "0047-259X",
    doi = "https://doi.org/10.1016/0047-259X(88)90145-5",
    url = "http://www.sciencedirect.com/science/article/pii/0047259X88901455",
    author = "Joseph S Verducci and Michael E Mack and Morris H DeGroot",
    keywords = "agreement, kappa, intraclass correlation, reliability, log-linear model, mixing distribution",
    abstract = "This paper addresses the problem of estimating the population coefficient of agreement kappa (κ) among a set of raters who independently classify a randomly selected subject into one of two categories. Of the many possible probability models for these classifications, only mixtures of binomial models incorporate random rater effects, although limiting forms of additive and multiplicative (log-linear) models may themselves be represented as mixtures of binomials. Mixture models also motivate a simple new estimator κx of κ that is appropriate in the important situation where one of the categories is rare. In the case of a rare category, simulations under multiplicative and mixture models demonstrate the substantially smaller mean squared error of κx compared to its more popular competitor. An example of psychiatric classification illustrates the plausibility of a simple mixture model as well as sizable discrepancies among estimators of κ."
}
