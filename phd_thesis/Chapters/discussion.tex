\chapter{Discussion}
% Ideas (not in order):
% \begin{itemize}
%   % Functional networks
%   \item Potential for more network science applications?
%   % COMb
%   \item Applied the COMB distribution to neuronal data for the first time.
%   \item investigated changes in response to stimulus, different for different regions
%   \item best fit
%   \item captures changes better than correlations, offers a good alternative to correlation for quantifying association
%   \item replicated stimulus related quenching
%   \item captures correlated behaviour by quantifying \textit{association}.
%   \item coupling with existing models could yield some nice models.
%   \item More statistical invention could be useful. Conway-Maxwell-Poisson distribution
% \end{itemize}

In this project, we attempted to address some of the challenges in data collection from large neuronal ensembles (specifically with calcium imaging) and some of the problems in analysing the data collected from large neuronal ensembles.

Firstly, we investigated the relationship between cell biochemistry, action potentials and the fluorescence traces produced by fluorescent calcium indicators. We did this by building a biophysical model that takes in a spike train and returns the fluorescence trace that that spike would induce. The model included mechanics for the binding of calcium to fluorescent and endogenous mobile and immobile buffers, and the consequent changes in concentration of free and bounded calcium. The model consisted of $17$ parameters, $13$ of which were set according to data from the literature, and $4$ of which were free parameters. We trained the model using simultaneously collected spiking and calcium imaging data \parencite{berens}. We fitted the model by matching the $\Delta F/F_0$ in response to an action potential, and by matching the power spectrum of the actual fluorescence trace. This meant that our model would include the correct amount of noise as well as return the correct change in amplitude in response to an action potential.

Since our model produced fluorescence traces, we could apply spike inference algorithms to the modelled fluorescence traces that our model produced after training, and compare the performance of the algorithms on the modelled traces to their performance on the real traces. We used three spike inference algorithms, two of which were based on modelling the calcium trace as an autoregression \parencite{friedrich, pnevmatikakis}, and another inference algorithm that was a little more biologically inspired, but amounted to a very similar algorithm \parencite{deneux}. We compared the performance of the algorithms by using them to infer spikes from $20$ real and modelled fluorescence traces induced by $20$ corresponding real spike trains. We then used several binary classification measures (true positive rate, accuracy etc.) to asses the quality of the spike inference for the real and modelled fluorescence traces. We found that the spike inference algorithms performed similarly on real and modelled traces, showing that our model is capturing at least some of the characteristics of the real fluorescence traces.

In order to investigate the effect of indicator characteristics on the modelled fluorescence trace and spike inference quality, we perturbed the indicator's affinity and dissociation rate in parallel, keeping the ratio of the two the same for all perturbations. We measured the SNR of the trace, and the true positive rate of the spike inference algorithms at each perturbed value pair. We found that perturbing the values lower caused in decrease in SNR and spike inference quality. This shows that our model could be used to test theoretical fluorescent calcium indicators without having to actually manufacture them. Experimental neuroscientists could also use our model to judge which indicator characteristics are most influential in their experimental context.

We then investigated the effect of perturbing buffer concentration, and indicator concentration, on the signal-to-noise ratio of the modelled fluorescence trace and spike inference quality. This was a worthwhile experiment because endogenous buffer concentrations vary from cell to cell \parencite{bartol, maravall, neher}, as does indicator expression \parencite{chen}. We found that extreme perturbations away from the indicator concentration taken from the literature lowered the SNR of the trace, and the spike inference quality. We also found that increases in the concentration of endogenous buffer above the value taken from the literature caused a decrease in the SNR and spike inference quality. This reiterates that the indicator and endogenous buffers compete to bind with free calcium molecules, and this has an effect on fluorescence and consequently on spike inference.

We then created some synthetic spike trains with controlled mean firing rates sampled the rates from an Ornstein-Uhlehnbeck process. We found that the higher the firing rate, the lower the accuracy of the spike inference algorithms. But the mean firing could perhaps be inferred from the amplitude of the fluorescence traces. The higher firing rate, the higher the amplitude. Calibrating the model to facilitate and accurate measurement would require some kind of ground truth, but relative comparisons could be made without any other knowledge of the underlying spiking process.

One obvious limitation to our model is the lack of binding mechanics for both the indicator and endogenous buffers. Greenberg et al included these mechanics in their successful spike inference model. We felt that the timescale of these binding mechanics was so small in comparison to the fluorescence dynamics that omitting them would make no difference. But it is possible that their inclusion would improve our model.

After investigating the difficulties with inferring spiking data from calcium imaging data, we moved from data collection to analysis and we decided to implement a new network analysis method on data from a neuronal ensemble. Using an electrophysiological dataset with spike sorted data from $9$ different brain regions in $3$ mice \parencite{steinmetz}, we binned the spike times for each cell into spike counts for each cell and measured the correlation coefficients between these spike counts for a selection of cells evenly distributed across the $9$ regions. We repeated these measurements for time bin widths ranging from $5$ms to $3$s. We rectified these measurements and, for a given time bin width, used them as weights for a weighted undirected graph where each node represents a neuron, and the weight of each edge is the correlation between the neurons represented by the nodes on that edge. We applied a novel spectral analysis and community detection method \parencite{humphries} to this network. This clustered the nodes in our ensemble into communities whose behaviour was more correlated than expected. Our measure of 'expected correlation strength' were based on a random network that matched our data network's sparsity and total weight. We compared the detected communities to the anatomical division of our cells using clustering comparison measures. We then conditioned the binned spike counts on the behaviour of the mouse using the principal components of a video of the mouses face recorded simultaneously with the electrophysiology. We broke the total covariance down into `spike count covariance' and `signal covariance' components  conditioning on the behavioural data and using the law of total covariance. We then repeated our analysis for spike count correlations, and signal correlation. Finally, since our community detection method was only valid on graphs with non-negative weights, we used different methods for creating a non-negative graph from our total correlations, and we repeated our analysis on those graphs.

Our first finding was that the time bin width used to bin spike times into spike counts had a effect on the mean magnitude of the correlations measured. The wider the bin, the higher the correlations. Not only that, we separated the pairs into positively and negative correlated pairs, and we found that positively correlated pairs have greater correlation coefficients when using a wider bin, and negatively correlated pairs have more negative correlation coefficients when using a wider bin. We also found that the width of the bin used had an effect on the distribution of the spike counts. For smaller bin widths, the distribution of spike counts was better represented by a skewed distribution like the Poisson distribution. For wider bins, the spike counts were better represented by a Gaussian distribution.

Next we investigated the differences between correlations within regions and between regions. When we divided the pairs according to those two groups, we found that the mean within-region correlations were higher at every bin width, and the difference between the two means grew with increasing bin width. When we split the pairs of cells according to their regions, we found that the mean within-region correlations in any given region were usually greater than the mean between-region correlations for any region pair involving that region. The difference between the mean within-region correlation and the highest between-region correlations involving that region grew smaller with increasing bin width. To investigate this further, we plotted these mean correlations in matrices. Although the mean within-region correlations were usually the highest value in their row or column, as the bin width increased, the mean between-region correlations grew in magnitude relative to the within-region figure.

Next we chose a null network model, and we used the `Network Noise Rejection' process \parencite{humphries} to check for additional structure in our correlation based data network that was not captured by the null model. We found additional structure for any bin width that we used. We also found that the dimensionality of the additional structure reduced as we increased the bin width. This could mean that the processes or representations that take place over longer timescales within the brain also take place in a lower dimensional space.

We applied a community detection method \parencite{humphries2} to the signal correlation networks arising from the network noise rejection. We found that the number of communities detected decreased with increasing bin width. We also noticed that at shorter bin widths, the detected communities were more likely to consist of cells from one  brain region only. We investigated this further by using clustering comparison methods to compare the detected communities with the anatomical division of the cells. We found that for short timescales $<50$ms correlated communities tended to exist within anatomical regions, and for longer timescales $>100$ms, the correlated communities tended to exist across anatomical regions. This is broadly in agreement with a similar finding for EEG data from humans performing semantic or memory tasks \parencite{von_stein}. Von Stein et al. (2000) found that visual processing taking place locally in the visual system was captured in the gamma frequency range ($25-70$Hz), while semantic processing was captured in the beta range ($12-18$Hz), and tasks involving mental imagery and working memory retention were captured in the theta and alpha ranges ($4-8$Hz, and $8-12$Hz respectively).

We then conditioned our correlation measures on the the mouse's behaviour. This allowed us to create spike count correlation (or noise correlation) networks, and signal correlation networks \parencite{cohen2}. We applied our analysis to these networks. For the spike count correlation networks we found very similar results to the total correlation networks. More communities at smaller bin widths, and communities resembled the anatomical division at smaller bin widths. Given that recent findings show that behaviour can account for correlated spiking in many areas of the brain \parencite{stringer}, these results for the spike count correlation show that this correlated behaviour is still processed locally at short timescales, while processes and representations that take more time make use of correlated activity across multiple regions.

For the signal correlations, we still found additional structure in these networks. But we always detected a smaller number of communities. These communities also had no relation to the anatomical division of the cells. This result shows that there are groups of cells across multiple brain regions that are activated similarly by certain behaviours.

All of the networks so far were based on rectified correlation measures, because the network noise rejection and community detection processing is (currently) only valid for networks with non-negative weights. For the final part of our analysis, we tried different ways of transforming our total correlations into non-negative quantities before applying our analysis. First of all we took the absolute value of our correlation measures. Our results were very similar to those for the rectified correlations with the exception that we detected more communities consistently. It is possible that using this method detects both positively and negatively correlated communities.

We also tried reversing the sign of all the correlations, then rectifying the network. We hope that this would allow us to detect the negatively correlated communities. We did detect communities in these networks, but never more than three, and these communities bore no relationship with the anatomical distribution of the cells.

There is a lot of potential for network science applications in computational neuroscience. For example, some pairwise measure other than correlation coefficients could be used as the weights of the graph. The synaptic connections between cells can be isolated in-vitro \parencite{okun}. A map of these synaptic connections could be used as the basis for directed graphs. The analysis methods applicable to directed graphs could give insights about the formation of synaptic connections, or the dynamic changes in these connections over time. Other methods of community detection could be used on directed or undirected graphs. We used a `hard' clustering method in our research, that is, each neuron could be a member of one cluster/community only. `Fuzzy-clustering' methods do exist, where each element of the set to be clustered could be a member of more than one cluster \parencite{baadel}.

Having spent much time investigating correlated behaviour using coefficients of spike counts, we decided to try another method for capturing correlated behaviour in neuronal ensembles. We used electrophysiological data taken from $5$ brain regions of an awake mouse exposed to visual stimuli \parencite{steinmetz2019}. We modelled the number of active neurons in a given brain region as the number of successes in a collection of dependent Bernoulli random variables using the Conway-Maxwell-binomial distribution. To avoid violating the Bernoulli assumption, we binned the spike times using $1$ms bins. The Conway-Maxwell-binomial distribution is a two parameter extension of the standard binomial distribution. The extra parameter allows the distribution to capture possible positive or negative association between the Bernoulli trials \parencite{kadane_2016}. This means that we are assuming that all the neurons are dependent in the same way. This is not an accurate assumption, but it allows us model the data in a simple way.

First of all we established that there were changes in the number of active neurons in response to the visual stimuli. This was the case in the hippocampus, thalamus, and primary visual cortex. Each region had its own signature response. We measured the mean and variance of the number of active neurons in a sliding window starting before stimulus onset, and finishing after the end of stimulus presentation.

As well as the Conway-Maxwell-binomial distribution, we also fitted binomial, and beta-binomial distributions to the number of active neurons in a sliding window. We found that the Conway-Maxwell-binomial distribution was the best fit for over $90\%$ of the samples. This means that the COMb distribution is capturing some dependency between the neurons, because the binomial distribution assumes independence. Also the COMb distribution captures this dependence more accurately than the beta-binomial distribution, which does have some capacity for over dispersion.

Next we showed that the Conway-Maxwell-binomial distribution captured the change in association at stimulus onset better than the correlation coefficient. The extremely small bin width artificially shrunk the correlation coefficient to the point where this measurement didn't detect any correlated activity. But the association parameter of the COMb distribution detected some positive association between the neurons at stimulus onset. So, for particularly short time bins, where neurons can be treated as Bernoulli random variables, the Conway-Maxwell-binomial distribution is a good way to capture correlated behaviour. There are other measurements for capturing association to which this distribution should be compared. Cross-correlograms could be used for some measure of synchrony, for example.

Finally, we replicated a famous finding of Churchland et al. (2010) relating to the quenching of neural variability at stimulus onset, thereby finding a parallel between this reduction in the Fano factor and a reduction in the association parameter of the COMb distribution.

We showed that computational neuroscientists can make progress by being inventive with their statistical models. A similar distribution to investigate would be the Conway-Maxwell-Poisson distribution. This is similar to the standard Poisson distribution, but with an additional parameter that allows for over- or under- dispersion relative to a Poisson distribution. This might be ideal for modelling firing rates of individual neurons. Some interaction between the fitted parameters could capture the association between neurons.

There is one technology that has the potential to take over from both electrophysiology and calcium imaging. The technique of voltage imaging has become more useful in recent years. The aim for neuroscience would be to develop a voltage imaging dye or protein that images the membrane potential of a neuron with enough spatial and temporal resolution to detect action potentials. The voltage imaging dyes that have been developed so far do not have high enough spatial resolution to single out individual cells in-vivo using staining \parencite{bando}. But, genetically encoded voltage indicators have been developed that have high enough resolution to indicate individual spikes and subthreshold activity from small numbers of cells in the striatum, hippocampus, and cortex of awake behaving mice \parencite{piatkevich}. These indicators have the potential to take over from calcium imaging, and if imaging deep within the brain becomes possible, electrophysiology could also be replaced. This is speculation, but the potential is there.
